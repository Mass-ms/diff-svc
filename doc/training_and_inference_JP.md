# Diff-SVC(train/inference by yourself)
## 0. 環境設定
>お知らせ: 要件ファイルが更新され、3つのバージョンから選択できるようになりました。
 
1. requirements.txtには、開発・テスト時の全環境が含まれています。Torch1.12.1+cu113が含まれており、pipで直接インストールするか、中のPyTorch関連のパッケージ（torch/torchvision）を削除してからpipでインストールし、独自のtorch環境を使用することが可能です。
    ```
    pip install -r requirements.txt
    ```
2. **(推奨)**: `requirements_short.txt` は上のものを手動で整理したものですが、トーチ本体は含まれていません。また、以下のコードを実行するだけでもOKです。
    ```
    pip install -r requirements_short.txt
    ```
3. プロジェクトのルートディレクトリの下に @三千がコンパイルした要件リスト (requirements.png) があり、これは某ブランドのクラウドサーバーでテストされたものです。しかし、そのtorchバージョンはもう最新のコードとは互換性がありませんが、他の要件のバージョンは参考として使うことができます。

## 1. 推論
>プロジェクトのルートディレクトリにある `inference.ipynb` を使うか、@IceKyrin が書いた `infer.py` を筆者が推論用にアレンジしたものを使うことができます。
最初のブロックにある以下のパラメータを編集してください。
```
config_path= 'location of config.yaml in the checkpoints archive'
# E.g.: './checkpoints/nyaru/config.yaml'
# コンフィグとチェックポイントは一対一で対応しています。他のコンフィグファイルは使用しないでください。

project_name='name of the current project'
# E.g.: 'nyaru'

model_path='full path to the ckpt file'
# E.g.: './checkpoints/nyaru/model_ckpt_steps_112000.ckpt'

hubert_gpu=True
# 推論時にHuBERT（モデル内のモジュール）にGPUを使用するかどうか。モデルの他の部分には影響しない。 
# 現在のバージョンでは、HuBERTモジュールの推論を行う際のGPU使用率を大幅に削減しています。1060 6GのGPUで完全な推論が可能なため、オフにする必要はありません。
# また、長い音声の自動スライスがサポートされました（inference.ipynbとinfer.pyの両方がサポートしています）。30秒以上の音声は、@IceKyrinのコードのおかげで、無音部分で自動的にスライスされるようになりました。
```
### 調整可能なパラメータ
```
wav_fn='xxx.wav'  
# 入力オーディオへのパス。デフォルトのパスは、プロジェクトのルートディレクトリにあります。

use_crepe=True  
# CREPEはF0抽出アルゴリズムである。性能は良いが、遅い。これをFalseに変更すると、若干劣るがはるかに高速なParselmouthアルゴリズムが使用される。

thre=0.05  
# CREPEのノイズフィルタリングの閾値。入力音声がクリーンな場合は増加させることができますが、入力音声にノイズがある場合は、この値を維持するか、または減少させます。このパラメータは、前のパラメータがFalseに設定されている場合、何の効果もありません。

pndm_speedup=20  
# 推論加速度の倍率。デフォルトの拡散ステップ数は1000なので、この値を10に変更すると、100ステップで合成することになる。デフォルトの20は適度な値である。この値は50倍（20ステップで合成）までなら明らかな品質低下はありませんが、それ以上では大幅な品質低下を招く可能性があります。注意：下のuse_gt_melが有効な場合、この値がadd_noise_stepより小さいことを確認してください。また、この値は、拡散ステップ数で割り切れる値である必要があります。

key=0
# Transpose パラメーターです。デフォルト値は0です（1ではありません！）。入力された音声のピッチを{key}半音ずつずらし、合成します。例えば、男性の声を女性の声に変えるには、この値を8や12などに設定します（12は1オクターブ上へシフトします）。

use_pe=True
# Melスペクトログラムからオーディオを合成するためのF0抽出アルゴリズム。Falseに変更すると、入力オーディオのF0が使用されます。
# TrueとFalseを使用した場合、結果に若干の違いがあります。通常はTrueにした方が良いですが、必ずそうなるわけではありません。合成速度にはほとんど影響しません。
# (キーパラメータの値が何であるかにかかわらず、この値は常に変更可能であり、影響を及ぼさない)
# 44.1kHzの機種ではこの機能はサポートされていないため、自動的にOFFになります。オンにしておいても同様にエラーは発生しません。

use_gt_mel=False
# このオプションは、AIペイントの画像間機能に類似しています。Trueに設定すると、出力音声は入力話者とターゲット話者の音声の混合となり、その混合比は以下のパラメータで決定されます。
# 注意!!!このパラメータがtrueに設定されている場合、移調はサポートされていないため、keyパラメータが0に設定されていることを確認してください。

add_noise_step=500
# 前のパラメータと関連し、入力音声とターゲット音声の比率を制御します。1を指定すると完全に入力音声となり、1000を指定すると完全にターゲット音声となります。300程度にすると、両者がほぼ均等に混ざった状態になります。(この値は線形ではないので、このパラメータが非常に低い値に設定されている場合は、pndm_speedupを下げて合成の質を高めることができます)


wav_gen='yyy.wav'
# 出力する音声へのパス。デフォルトはプロジェクトのルートディレクトリにあります。ここでファイル拡張子を変更することで、ファイルタイプを変更することができます。
```

infer.pyを使用する場合、パラメータの変更方法は同様です。 `__name__=='__main__'` 内の値を変更し、プロジェクトのルートディレクトリで `python infer.py` を実行します。この方法では、入力音声をraw/の下に、出力音声をresults/の下に置く必要があります。

## 2. データ作成・トレーニング
### 2.1 データ作成
>現在、WAVとOggの両フォーマットのオーディオに対応しています。サンプリングレートは24kHz以上であることが望ましいです。サンプリングレートとチャンネル数の問題は、プログラムが自動的に処理します。サンプリングレートは16kHz以下であるべきではありません（通常はそうではありません）。 \
音声は5～15秒のセグメントに分割するのがよいでしょう。音声の長さは特に決まりはありませんが、長すぎず短すぎずがベストです。音声は、BGMや他の声がない、できれば過度のリバーブなどがかかっていない、対象話者のドライなボーカルである必要があります。音声を抽出処理する場合は、できるだけ高音質でお願いします。 \
現在、一人用のトレーニングのみ対応しています。音声の総時間は3時間以上であることが必要です。ラベル付けは必要ありません。音声ファイルは後述のraw_data_dirの下に置くだけです。このディレクトリの構造は重要ではなく、プログラムが勝手にファイルを探します。

### 2.2 ハイパーパラメータの編集
>まず、config.yaml（このファイルは24kHzのボコーダ用です。44.1kHzのボコーダにはconfig_nsf.yamlを使います）のバックアップを取って、それを編集します。
以下のようなパラメータを使用します（プロジェクト名nyaruを例としています）。
```
K_step: 1000
# 拡散ステップの総数。変更することはお勧めしません。

binary_data_dir: data/binary/nyaru
# 処理前データのパス：最後の部分は、現在のプロジェクト名に変更する必要があります。

config_path: training/config.yaml
# 使用するconfig.yaml自体へのパス。前処理でこのファイルにデータを書き込むので、yamlファイルが格納される場所へのフルパスである必要があります。

choose_test_manually: false
# テストセットを手動で選択する。デフォルトでは無効になっており、プログラムは自動的に5つのオーディオファイルをテストセットとしてランダムに選択します。
# true に設定すると、test_prefixes にテストファイルのファイル名の接頭辞を入力します。プログラムは、対応する接頭辞で始まるファイルをテストセットとして使用します。
# これはリストであり、例えば複数の接頭辞を含むことができます。
test_prefixes:
- test
- aaaa
- 5012
- speaker1024
# 重要：テストセットを空にすることはできません。意図しない効果を避けるため、テストセットを手動で選択しないことをお勧めします。

endless_ds:False
# データセットが小さすぎる場合、各エポックが非常に速く過ぎてしまいます。これをTrueに設定すると、1000エポックを1つのエポックとして扱います。

hubert_path: checkpoints/hubert/hubert.pt
# HuBERTモデルへのパス、このパスが正しいことを確認します。ほとんどの場合、解凍されたcheckpoints.zipアーカイブが正しいパスの下にモデルを置くので、編集は必要ありません。現在、torchバージョンは推論に使用されています。

hubert_gpu:True
# プリプロセスの際にHuBERT（モデル内のモジュール）にGPUを使用するかどうか。Falseに設定するとCPUが使用され、処理時間が大幅に増加する。なお、推論時にGPUを使用するかどうかは、推論時に別途制御され、この影響を受けない。HuBERTがtorch版に変わってから、現在1060 6GのGPUでVRAMの制限を超えずにプリプロセスと推論オーディオを1分以下で実行できるようになっているので、通常はFalseに設定する必要はないでしょう。

lr: 0.0008
# 初期学習率：この値はバッチサイズ88に対応する。バッチサイズが小さい場合は、この値を少し下げるとよい。

decay_steps: 20000
# 20,000ステップごとに、学習率は元の半分まで減衰します。バッチサイズが小さい場合は、この値を大きくしてください。

# 30-40程度のバッチサイズであれば、lr=0.0004，decay_steps=40000が推奨値です。

max_frames: 42000
max_input_tokens: 6000
max_sentences: 88
max_tokens: 128000
# バッチサイズは、これらのパラメータに基づいて動的に計算されます。これらのパラメータの正確な意味が不明な場合は、max_sentences パラメータのみを変更し、VRAM の制限を超えないようにバッチサイズの上限を設定することができます。

pe_ckpt: checkpoints/0102_xiaoma_pe/model_ckpt_steps_60000.ckpt
# peモデルへのパス。このファイルが存在することを確認する。用途は推論の項を参照。

raw_data_dir: data/raw/nyaru
# 前処理を行う前の生データのディレクトリへのパス。生の音声ファイルはこのディレクトリの下に置いてください。中の構造は、プログラムが自動的に解析しますので、問題ありません。

residual_channels: 384
residual_layers: 20
# コアネットワークの大きさを制御するパラメータ群。値を大きくすると、ネットワークのパラメータが増え、学習速度が遅くなりますが、必ずしも良い結果につながるとは限りません。より大きなデータセットの場合、最初のパラメータを512に変更することができる。自分で実験してみるといい。しかし、何をやっているのかよくわからない場合はそのままにしておくのが一番です。

speaker_id: nyaru
# 対象となる話者の名前。現在のところ、single-speakerのみサポートされている。(このパラメータは参照用であり、機能的な影響はない)

use_crepe: true
# CREPE を使用して、前処理に必要な F0 を抽出します。有効にしておくとより良い結果が得られ、無効にしておくとより高速に処理できます。

val_check_interval: 2000
# テストセットで推論を行い、2000ステップごとにチェックポイントを保存する。

vocoder_ckpt:checkpoints/0109_hifigan_bigpopcs_hop128
# 24kHzの機種では、対応するボコーダーのディレクトリへのパスとします。44.1kHzの場合は、対応するボコーダーのファイルそのものへのパスです。間違えないように注意してください。

work_dir: checkpoints/nyaru
# 最後の部分をプロジェクト名に変更します。(または、このディレクトリを自動的に生成するために、削除するか完全に空のままにしておくこともできますが、ランダムな名前をつけないようにします)

no_fs2: true
# ネットワークエンコーダの簡略化。モデルサイズを小さくし、学習を高速化することができる。ネットワーク性能にダメージを与える直接的な証拠は今のところ見つかっていない。デフォルトで有効。

```
> 名前から判断してわかりそうな場合でも、何をしているかわからない場合は、他のパラメータを編集しないでください。

### 2.3 データ前処理
diff-svcディレクトリの下で以下のコマンドを実行します。 \
#windows
```
set PYTHONPATH=.
set CUDA_VISIBLE_DEVICES=0
python preprocessing/binarize.py --config training/config.yaml
```
#linux
```
export PYTHONPATH=.
CUDA_VISIBLE_DEVICES=0 python preprocessing/binarize.py --config training/config.yaml
```
前処理については、@IceKyrinさんがHuBERTとその他の機能を別々に処理するコードを用意してくれています。VRAMが足りなくて普通にできない場合は、まず`python ./network/hubert/hubert_model.py` を実行して、それから前処理コマンドを実行すれば、前処理されたHuBERTの特徴を認識することができます。

### 2.4 トレーニング
#windows
```
set CUDA_VISIBLE_DEVICES=0
python run.py --config training/config.yaml --exp_name nyaru --reset 
```
#linux
```
CUDA_VISIBLE_DEVICES=0 python run.py --config training/config.yaml --exp_name nyaru --reset
```
>`exp_name` をプロジェクト名に変更し、コンフィグパスを編集する必要があります。トレーニングに使用するコンフィグファイルは、プリプロセッシングに使用するコンフィグファイルと同じものであることを確認してください。\
重要：学習終了後（クラウド上）、ローカルで前処理を行わなかった場合、対応するckptファイルと推論用の設定ファイルをダウンロードする必要があります。前処理は設定ファイルにデータを書き込むので、ローカルマシンにあるものは使用しないでください。推論に使用する設定ファイルは、プリプロセスで使用したものと同じであることを確認してください。

### 2.5 想定される問題

>**2.5.1 'Upsample' オブジェクトに 'recompute_scale_factor' 属性がない。**\
この問題はcuda 11.3に対応するtorchのバージョンで発見されました。この問題が発生した場合、pythonパッケージ内の`torch.nn.modules.upsampling.py` ファイル（例えば、conda環境では、conda_direnvs_environment_dir﹑Libsite-packages﹑torch﹑nnmodules﹑upsampling.py ） の 153-154 行目を編集してください。
```
return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners,recompute_scale_factor=self.recompute_scale_factor)
```
>を
```
return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners)
# recompute_scale_factor=self.recompute_scale_factor)
```

>**2.5.2 'utils'という名前のモジュールがありません**\
実行環境（colab notebooksなど）で、以下のように設定してください。
```
import os
os.environ['PYTHONPATH']='.'
!CUDA_VISIBLE_DEVICES=0 python preprocessing/binarize.py --config training/config.yaml
```
この作業は、プロジェクトのルートディレクトリで行う必要があることに注意してください。

>**2.5.3 ライブラリ 'libsndfile.so' をロードすることができません。**\
Linux環境で発生する可能性のあるエラーです。以下のコマンドを実行してください。
```
apt-get install libsndfile1 -y
```
>**2.5.4 import 'consume_prefix_in_state_dict_if_present' を読み込むことができません。**\
現在のtorchのバージョンは古すぎます。より高いバージョンのtorchにアップグレードしてください。

>**2.5.5 データの前処理が遅い**\
configで `use_crepe` が有効になっているか確認してください。これをオフにすると、速度が大幅に向上します。\
`hubert_gpu` が config で有効になっているか確認する。

その他、ご質問等ございましたら、QQチャンネルやDiscordサーバーにご参加いただき、お気軽にお尋ねください。
